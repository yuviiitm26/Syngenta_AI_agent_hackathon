ğŸ” Hybrid AI Agent with Claude 3.5 â€“ SQL + Document Reasoning
This project implements an intelligent Hybrid AI Agent capable of answering natural language queries by reasoning over both:

ğŸ“Š Structured data from a SQL database, and

ğŸ“„ Unstructured policy documents using retrieval-augmented generation (RAG).

It uses Claude 3.5 Sonnet for language understanding and Chain-of-Thought (CoT) prompting to route and resolve queries through the appropriate pipeline.

ğŸš€ Key Features
ğŸ” Query Type Classification
Automatically classifies user queries into SQL, Document, or Hybrid categories using CoT-based reasoning.

ğŸ§  Hybrid Reasoning
Combines document understanding (via FAISS vector store) and database results to answer complex queries grounded in policy definitions.

ğŸ“ Document QA with RAG
Uses FAISS to retrieve top-k relevant documents and prompts Claude to answer based on context.

ğŸ—„ï¸ SQL Generation + Execution
Converts natural language to executable SQL queries with schema grounding, executes on PostgreSQL, and returns result.

ğŸ” SQL Retry Mechanism
Detects hallucinated SQL errors (e.g., non-existent columns), patches and retries automatically.

ğŸ“Š Real-Time Performance Metrics
Logs query response time, estimated Claude token usage, and cost for every interaction.

ğŸ› ï¸ Tech Stack
LLM: Claude 3.5 Sonnet via custom API proxy

Vector Store: FAISS

Database: PostgreSQL

Backend: Python

frontend: Streamlit UI for live querying

Monitoring: Console logs (timing, cost, tokens)

ğŸ“ˆ Metrics Tracked
â±ï¸ Response Time

ğŸ§¾ Token Usage (Input + Output)

ğŸ’° Cost Estimation

ğŸ” Document Retrieval Latency

ğŸ›¢ï¸ SQL Execution Time

ğŸ”„ Hybrid Integration Time

ğŸ§ª Example Use Cases
"What are the return policies for damaged items?" â†’ Document QA

"Show orders with delivery delay over 7 days" â†’ SQL Query

"List employees classified under 'non-compliant' by the latest policy" â†’ Hybrid Reasoning

ğŸ“ Project Structure
app/
â”œâ”€â”€ __pycache__/                # Python cache files (auto-generated)
â”œâ”€â”€ data/                      # Input CSVs, PDFs, or data files
â”œâ”€â”€ faiss_index/               # FAISS index files for vector search
â”œâ”€â”€ keys/                      # API keys or credentials (exclude from Git!)
â”œâ”€â”€ main.py                    # ğŸš€ Entry point for the Streamlit app
â”œâ”€â”€ faiss_create.py            # Script to generate FAISS index from documents
â””â”€â”€ utils/
          â”œâ”€â”€ load_csv.py             # CSV loader utility for database
          â”œâ”€â”€ db.            # SQLAlchemy DB connection and utilities
ğŸ“Œ Future Improvements

LangChain integration

Advanced memory & feedback loop

Token caching to reduce repeated LLM calls

ğŸ¤ Contributing
PRs and suggestions are welcome! Feel free to raise issues or propose improvements for more efficient hybrid reasoning.
